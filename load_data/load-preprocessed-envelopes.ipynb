{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2f0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import eelbrain\n",
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Data locations\n",
    "DATA_ROOT = Path(\"~\").expanduser() / 'Data' / 'cocoha'\n",
    "DATA_PREPROC = DATA_ROOT / \"data_preprocessed\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "675d4cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files for S5 already exist, skipping.\n",
      "Files for S15 already exist, skipping.\n",
      "Files for S11 already exist, skipping.\n",
      "Files for S1 already exist, skipping.\n",
      "Files for S4 already exist, skipping.\n",
      "Files for S14 already exist, skipping.\n",
      "Files for S10 already exist, skipping.\n",
      "Files for S17 already exist, skipping.\n",
      "Files for S7 already exist, skipping.\n",
      "Files for S18 already exist, skipping.\n",
      "Files for S3 already exist, skipping.\n",
      "Files for S13 already exist, skipping.\n",
      "Files for S8 already exist, skipping.\n",
      "Files for S16 already exist, skipping.\n",
      "Files for S6 already exist, skipping.\n",
      "Files for S2 already exist, skipping.\n",
      "Files for S9 already exist, skipping.\n",
      "Files for S12 already exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in DATA_PREPROC.glob(\"*.mat\"):\n",
    "\n",
    "    SUBJECT = file.stem.split(\"_\")[0]\n",
    "\n",
    "    dst_dir = DATA_ROOT / 'envelopes' / SUBJECT\n",
    "    dst_dir.mkdir(exist_ok=True, parents=True)\n",
    "    attended_dst = dst_dir / f'{SUBJECT}_attended_envelope.pickle'\n",
    "    unattended_dst = dst_dir / f'{SUBJECT}_unattended_envelope.pickle'\n",
    "    if attended_dst.exists() and unattended_dst.exists():\n",
    "        print(f\"Files for {SUBJECT} already exist, skipping.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    print(\"Saving ~\", SUBJECT, \"...\")\n",
    "\n",
    "    mat = loadmat(file, squeeze_me=True, struct_as_record=False)\n",
    "    data = mat['data']\n",
    "\n",
    "    # --- collect all trials ---\n",
    "    att_envelope_trials = []\n",
    "    unatt_envelope_trials = []\n",
    "\n",
    "    for att_envelope, unatt_envelope in zip(data.wavA, data.wavB):  # 60 trials\n",
    "        att_envelope_trials.append(att_envelope)\n",
    "        unatt_envelope_trials.append(unatt_envelope)\n",
    "\n",
    "    # --- concatenate trials ---\n",
    "    att_envelope_concat = np.concatenate(att_envelope_trials)\n",
    "    unatt_envelope_concat = np.concatenate(unatt_envelope_trials)\n",
    "\n",
    "    # Create time axis\n",
    "    time_axis = eelbrain.UTS(0, 1/64, len(att_envelope_concat))  # assuming 64 Hz\n",
    "\n",
    "    # Save the attended and unattended envelopes as NDVars\n",
    "    att_ndvar = eelbrain.NDVar(att_envelope_concat, dims=(time_axis,), name='attended')\n",
    "    eelbrain.save.pickle(att_ndvar, attended_dst)\n",
    "\n",
    "    unatt_ndvar = eelbrain.NDVar(unatt_envelope_concat, dims=(time_axis,), name='unattended')\n",
    "    eelbrain.save.pickle(unatt_ndvar, unattended_dst)\n",
    "    print(f\"Saved attended and unattended envelopes for {SUBJECT}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a9c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eelbrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
