{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25185414-a855-46d0-921b-223a4f522e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import eelbrain\n",
    "from eelbrain import UTS, NDVar\n",
    "import mne\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05d4cc5b-7fb5-48f0-a5c9-79c8bd684ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "# Data locations\n",
    "#BASE_DIR = Path.cwd()\n",
    "BASE_DIR = Path(\"~\").expanduser() / 'Data' / 'cocoha2' # <---- Uncomment this if you are working with files in data root directory\n",
    "\n",
    "DATA_PREPROC = BASE_DIR / \"data_preprocessed\"\n",
    "PREDICTOR_DIR = BASE_DIR / 'predictors'\n",
    "TRF_DIR = BASE_DIR / 'TRFs'\n",
    "PREDICTOR_DIR.mkdir(exist_ok=True)\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "STIMULUS_DIR = BASE_DIR / 'stimuli'\n",
    "EEG_DIR = BASE_DIR / 'eeg'\n",
    "EEG_DIR.mkdir(exist_ok=True)\n",
    "SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d+', path.name)]\n",
    "STIMULI = [stimulus.stem for stimulus in STIMULUS_DIR.glob(\"*.wav\")]\n",
    "\n",
    "# Constants\n",
    "LOW_FREQUENCY = 0.5\n",
    "HIGH_FREQUENCY = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd1485",
   "metadata": {},
   "source": [
    "# Creating predictors from stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f1f59d3-6fe7-4b80-8f5f-a8de88eb68a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Finished\n"
     ]
    }
   ],
   "source": [
    "# CREATE PREDICTORS (gammatone envelopes): envelope_log, envelope_onset, and envelope_words\n",
    "\n",
    "for stimulus in STIMULI:\n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # Define destination\n",
    "    dst = STIMULUS_DIR / f'{stimulus}-gammatone.pickle'\n",
    "    \n",
    "    # Define all output paths\n",
    "    paths = [\n",
    "        PREDICTOR_DIR / f'{stimulus}~envelope-log.pickle',\n",
    "        PREDICTOR_DIR / f'{stimulus}~envelope-onset.pickle',\n",
    "        PREDICTOR_DIR / f'{stimulus}~envelope-log-8band.pickle',\n",
    "        PREDICTOR_DIR / f'{stimulus}~envelope-onset-8band.pickle',\n",
    "    ]\n",
    "    # Check if all files exist AND are loadable\n",
    "    for path in paths:\n",
    "        skip = False\n",
    "        if path.exists():\n",
    "            try:\n",
    "                existing_data = eelbrain.load.unpickle(path)\n",
    "                if existing_data is not None:\n",
    "                    skip = True\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: existing predictor file {path.name} is corrupted or unreadable, will recompute. ({e})\")\n",
    "    if skip:\n",
    "        #print(f\"All predictors for stimulus {stimulus} already exist and are valid, skipping...\")\n",
    "        continue\n",
    "    #print(f\"Processing stimulus {stimulus}\")\n",
    "\n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # Load the sound file corresponding to the predictors\n",
    "    wav = eelbrain.load.wav(STIMULUS_DIR / f'{stimulus}.wav')\n",
    "    # Apply a filter to make it high resolution\n",
    "    envelope = eelbrain.gammatone_bank(wav, 80, 15000, 128, location='left', tstep=0.001) \n",
    "\n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # Make the log envelope, and 8 band frequency version\n",
    "    envelope_log = (envelope + 1).log()\n",
    "    envelope_log_sum = envelope_log.sum('frequency')\n",
    "    envelope_log_8band = envelope_log.bin(nbins=8, func='sum', dim='frequency')\n",
    "    \n",
    "    # Make the onset envelope, and 8 band frequency version\n",
    "    envelope_onset = eelbrain.edge_detector(envelope_log, c=30)\n",
    "    envelope_onset_sum = envelope_onset.sum('frequency')\n",
    "    envelope_onset_8band = envelope_onset.bin(nbins=8, func='sum', dim='frequency')\n",
    "    \n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # Save pickles\n",
    "    eelbrain.save.pickle(envelope_log_sum, \n",
    "                         PREDICTOR_DIR / f'{stimulus}~envelope-log.pickle') # <-- This is referred to as gammatone-1 in document\n",
    "    eelbrain.save.pickle(envelope_onset_sum, \n",
    "                         PREDICTOR_DIR / f'{stimulus}~envelope-onset.pickle') # <-- This is referred to as gammatone-on-1 in document\n",
    "    eelbrain.save.pickle(envelope_log_8band, \n",
    "                         PREDICTOR_DIR / f'{stimulus}~envelope-log-8band.pickle') # <-- This is referred to as gammatone-8 in document\n",
    "    eelbrain.save.pickle(envelope_onset_8band, \n",
    "                         PREDICTOR_DIR / f'{stimulus}~envelope-onset-8band.pickle') # <-- This is referred to as gammatone-on-8 in document\n",
    "print('Process Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac458993-186c-4e08-908e-8a342eb73030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process finished\n"
     ]
    }
   ],
   "source": [
    "# DATA PROCESSING OF ENVELOPES\n",
    "\n",
    "SAMPLING_RATE = 1/64\n",
    "envelopes_log = {}\n",
    "envelopes_log_8band = {}\n",
    "envelopes_onset = {}\n",
    "envelopes_onset_8band = {}\n",
    "\n",
    "for stimulus in STIMULI:\n",
    "    # Resample spectrograms to 64 hz, offset and filter (data processing)\n",
    "    # Log\n",
    "    envelope_log = eelbrain.load.unpickle(PREDICTOR_DIR / f'{stimulus}~envelope-log.pickle')\n",
    "    envelope_log = envelope_log.bin(SAMPLING_RATE, dim='time', label='start')\n",
    "    envelope_log = eelbrain.pad(envelope_log, tstart=-0.100, tstop=envelope_log.time.tstop + 1, name='envelope_log')\n",
    "    envelope_log = eelbrain.filter_data(envelope_log, LOW_FREQUENCY, HIGH_FREQUENCY)\n",
    "    envelopes_log[stimulus] = envelope_log\n",
    "    # Log 8 band\n",
    "    envelope_log_8band = eelbrain.load.unpickle(PREDICTOR_DIR / f'{stimulus}~envelope-log-8band.pickle')\n",
    "    envelope_log_8band = envelope_log_8band.bin(SAMPLING_RATE, dim='time', label='start')\n",
    "    envelope_log_8band = eelbrain.pad(envelope_log_8band, tstart=-0.100, tstop=envelope_log_8band.time.tstop + 1, name='envelope_log_8band')\n",
    "    envelope_log_8band = eelbrain.filter_data(envelope_log_8band, LOW_FREQUENCY, HIGH_FREQUENCY)\n",
    "    envelopes_log_8band[stimulus] = envelope_log_8band\n",
    "    # Onset\n",
    "    envelope_onset = eelbrain.load.unpickle(PREDICTOR_DIR / f'{stimulus}~envelope-onset.pickle')\n",
    "    envelope_onset = envelope_onset.bin(SAMPLING_RATE, dim='time', label='start')\n",
    "    envelope_onset = eelbrain.pad(envelope_onset, tstart=-0.100, tstop=envelope_onset.time.tstop + 1, name='envelope_onset')\n",
    "    envelope_onset = eelbrain.filter_data(envelope_onset, LOW_FREQUENCY, HIGH_FREQUENCY)\n",
    "    envelopes_onset[stimulus] = envelope_onset\n",
    "    # Onset 8 band\n",
    "    envelope_onset_8band = eelbrain.load.unpickle(PREDICTOR_DIR / f'{stimulus}~envelope-onset-8band.pickle')\n",
    "    envelope_onset_8band = envelope_onset_8band.bin(SAMPLING_RATE, dim='time', label='start')\n",
    "    envelope_onset_8band = eelbrain.set_time(envelope_onset_8band, envelope_log.time, name='envelope_onset_8band')\n",
    "    envelope_onset_8band = eelbrain.filter_data(envelope_onset_8band, LOW_FREQUENCY, HIGH_FREQUENCY)\n",
    "    envelopes_onset_8band[stimulus] = envelope_onset_8band\n",
    "\n",
    "# Extract the duration of the stimuli, so we can later match the EEG to the stimuli\n",
    "# durations = [gt.time.tmax for stimulus, gt in zip(STIMULI, envelopes_log)]\n",
    "\n",
    "# Models\n",
    "# ------\n",
    "models = {\n",
    "    #'envelope_log': [envelopes_log],\n",
    "    # Compare different scales for the acoustic response\n",
    "    'envelope_log_8band': envelopes_log_8band,\n",
    "    # The acoustic edge detection model\n",
    "    #'envelope_log_onset': [envelopes_log, envelopes_onset],\n",
    "    #'envelope_onset_8band': [envelopes_onset_8band],\n",
    "    #'acoustic_8band': [envelopes_log_8band, envelopes_onset_8band],\n",
    "    # Models with word-onsets and word-class\n",
    "    #'words': [envelopes_words_onset],\n",
    "    #'words+lexical': [envelopes_words_onset, envelopes_words_lexical, envelopes_words_nlexical],\n",
    "    #'acoustic+words': [envelopes_log_8band, envelopes_onset_8band, envelopes_words_onset],\n",
    "    #'acoustic+words+lexical': [envelopes_log_8band, envelopes_onset_8band, envelopes_words_onset, \n",
    "    #                           envelopes_words_lexical, envelopes_words_nlexical],\n",
    "}\n",
    "print('Process finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efc8ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File S5_raw.fif already exists, skipping conversion for subject S5...\n",
      "File S15_raw.fif already exists, skipping conversion for subject S15...\n",
      "File S11_raw.fif already exists, skipping conversion for subject S11...\n",
      "File S1_raw.fif already exists, skipping conversion for subject S1...\n",
      "File S4_raw.fif already exists, skipping conversion for subject S4...\n",
      "File S14_raw.fif already exists, skipping conversion for subject S14...\n",
      "File S10_raw.fif already exists, skipping conversion for subject S10...\n",
      "File S17_raw.fif already exists, skipping conversion for subject S17...\n",
      "File S7_raw.fif already exists, skipping conversion for subject S7...\n",
      "File S18_raw.fif already exists, skipping conversion for subject S18...\n",
      "File S3_raw.fif already exists, skipping conversion for subject S3...\n",
      "File S13_raw.fif already exists, skipping conversion for subject S13...\n",
      "File S8_raw.fif already exists, skipping conversion for subject S8...\n",
      "File S16_raw.fif already exists, skipping conversion for subject S16...\n",
      "File S6_raw.fif already exists, skipping conversion for subject S6...\n",
      "File S2_raw.fif already exists, skipping conversion for subject S2...\n",
      "File S9_raw.fif already exists, skipping conversion for subject S9...\n",
      "File S12_raw.fif already exists, skipping conversion for subject S12...\n"
     ]
    }
   ],
   "source": [
    "# LOAD EEG FROM .mat to .fif\n",
    "for file in DATA_PREPROC.glob(\"*.mat\"):\n",
    "    SUBJECT = file.stem.split(\"_\")[0]\n",
    "\n",
    "    dst_dir = EEG_DIR / SUBJECT\n",
    "    dst_dir.mkdir(exist_ok=True)\n",
    "    dst = dst_dir / f'{SUBJECT}_raw.fif'\n",
    "    if dst.exists():\n",
    "        print(f\"File {dst.name} already exists, skipping conversion for subject {SUBJECT}...\")\n",
    "        continue\n",
    "\n",
    "    # Load the .mat file\n",
    "    mat = loadmat(file, squeeze_me=True, struct_as_record=False)\n",
    "    data = mat['data']\n",
    "\n",
    "    trials = []\n",
    "\n",
    "    for trial in data.eeg:  # 60 trials\n",
    "        eeg = trial[:, :64]    # remove extra channels\n",
    "        trials.append(eeg)\n",
    "    \n",
    "    # Concatenate trials along the time axis\n",
    "    eeg_data = np.concatenate(trials, axis=0).T  # Transpose to shape (n_channels, n_times)\n",
    "\n",
    "    ch_names = data.dim.chan.eeg[0][:64].tolist()\n",
    "\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=64, ch_types='eeg')\n",
    "\n",
    "    raw = mne.io.RawArray(eeg_data, info)\n",
    "    raw.set_montage('biosemi64')  # Set the montage to BioSemi 64\n",
    "\n",
    "    raw.save(dst, overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f46dcc4-054f-4217-9758-0746e761fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process finished\n"
     ]
    }
   ],
   "source": [
    "# LOAD EEG DATA\n",
    "\n",
    "# Create dictionaries to hold the eeg scans of each subject, and the predictors of each model\n",
    "subject_padded_eegs = {} \n",
    "n_trials = 60\n",
    "sampling_rate = 64\n",
    "\n",
    "for subject in SUBJECTS:\n",
    "    # Extract the raw files\n",
    "    raw = mne.io.read_raw(EEG_DIR / f'{subject}' / f'{subject}_raw.fif', preload=True)\n",
    "    # Filter the raw data to the desired band\n",
    "    raw.filter(LOW_FREQUENCY, HIGH_FREQUENCY, n_jobs=1)\n",
    "    # Interpolate bad channels\n",
    "    #raw.interpolate_bads() # <-- No bad filters so commented out\n",
    "\n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # load EEG data\n",
    "    eeg = eelbrain.load.mne.raw_ndvar(raw) # Load the raw data as NDVar 64 sensor, 192000 time\n",
    "    # EEG comes already concatenated, we must SPLIT, PAD in the right places, and then CONCATENATE back together\n",
    "    total_samples = eeg.shape[-1] \n",
    "    samples_per_trial = total_samples / n_trials\n",
    "    tstep = eeg.time.tstep\n",
    "    trial_duration = samples_per_trial * tstep\n",
    "\n",
    "    # SPLIT by trial duration in seconds\n",
    "    trials = [eeg.sub(time=(i*trial_duration, (i+1)*trial_duration)) for i in range(n_trials)]\n",
    "    # PAD each trial relative to trial start\n",
    "    padded_trials = [eelbrain.pad(trial, tstart=-0.100, tstop=(trial.time.tmax - trial.time.tmin + 1.0)) for trial in trials]\n",
    "    # Reset time for each trial to start at 0\n",
    "    n_samples = padded_trials[0].shape[-1] # This should give 3270 samples\n",
    "    padded_trials = [eelbrain.set_time(trial, UTS(0, 1/sampling_rate, n_samples+1)) for trial in padded_trials]\n",
    "    # CONCATENATE\n",
    "    eeg_padded = eelbrain.concatenate(padded_trials)\n",
    "    \n",
    "    # Update dictionaries\n",
    "    subject_padded_eegs[subject] = eeg_padded\n",
    "print('Process finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa2c17e9-f419-467b-8d34-66c097a81c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process finished\n"
     ]
    }
   ],
   "source": [
    "# GET PREDICTORS\n",
    "\n",
    "subject_model_predictors = {}\n",
    "expinfo_table = eelbrain.load.tsv(\"expinfo.csv\", encoding='utf-8-sig').as_dataframe()\n",
    "\n",
    "for subject in SUBJECTS:\n",
    "    # Update dictionaries\n",
    "    subject_model_predictors[subject] = {}\n",
    "\n",
    "    # Get predictors\n",
    "    for model, predictors in models.items():\n",
    "        # print(f\"Concatenating: {subject} ~ {model} predictors\")\n",
    "        # Select and concetenate the predictors corresponding to the EEG trials\n",
    "        predictors_concatenated = []\n",
    "        predictor_types = {'predictor': predictors}\n",
    "\n",
    "        for predictor_name, predictor in predictor_types.items():\n",
    "            trial_predictors = []\n",
    "            \n",
    "            for _, row in expinfo_table.iterrows():\n",
    "                if row['n_speakers'] == 1:\n",
    "                    continue\n",
    "                if row['attend_mf'] == 1:\n",
    "                    wavfile = row['wavfile_male']\n",
    "                else:\n",
    "                    wavfile = row['wavfile_female']\n",
    "                    \n",
    "                wavfile = wavfile.strip(\"'\")\n",
    "                path_key = wavfile.removesuffix('.wav')\n",
    "                trial_predictors.append(predictor[path_key])\n",
    "                \n",
    "            predictor_long = eelbrain.concatenate(trial_predictors)\n",
    "            #print(f\"  Predictor '{predictor_name}' trials: {len(trial_predictors)}\")\n",
    "            #print(f\"  Predictor '{predictor_name}' duration: {predictor_long.time.tstop:.2f}s\")\n",
    "            predictors_concatenated.append(predictor_long)\n",
    "            \n",
    "        subject_model_predictors[subject][model] = predictors_concatenated\n",
    "print('Process finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec69f1e8-b92b-4872-90d0-458192fc141c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eeg_padded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SANITY CHECK\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# make sure dimensions of eeg match predictors\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43meeg_padded\u001b[49m.time)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(predictors_concatenated[\u001b[32m0\u001b[39m].time)\n",
      "\u001b[31mNameError\u001b[39m: name 'eeg_padded' is not defined"
     ]
    }
   ],
   "source": [
    "# SANITY CHECK\n",
    "\n",
    "# make sure dimensions of eeg match predictors\n",
    "print(eeg_padded.time)\n",
    "print(predictors_concatenated[0].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4e91d-bd28-4dc6-ad95-d270bacfc061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————\n",
      "S4_data_preproc eeg extracted\n",
      "now boosting\n"
     ]
    }
   ],
   "source": [
    "# ESTIMATE TRF\n",
    "\n",
    "for subject in SUBJECTS:\n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # Make save directory\n",
    "    subject_trf_dir = TRF_DIR / subject\n",
    "    subject_trf_dir.mkdir(exist_ok=True)\n",
    "    trf_paths = {model: subject_trf_dir / f'{subject} {model}.pickle' for model in models}\n",
    "    # Skip this subject if all files already exist\n",
    "    #if all(path.exists() for path in trf_paths.values()): \n",
    "        #continue\n",
    "\n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # Load eeg\n",
    "    eeg = subject_padded_eegs[subject]\n",
    "    print('——————————————————————————————')\n",
    "    print(f'{subject} eeg extracted')\n",
    "\n",
    "    # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "    # Loop for estimating TRFs\n",
    "    for model, predictors in models.items():\n",
    "        # Skip if the file already exists\n",
    "        '''\n",
    "        skip = False\n",
    "        if path.exists():\n",
    "            try:\n",
    "                existing_trf = eelbrain.load.unpickle(path)\n",
    "                if existing_trf is not None:\n",
    "                    print(f\"TRF for {subject} ~ {model} already exists, skipping...\\n\")\n",
    "                    skip = True\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: existing TRF file for {subject} ~ {model} is corrupted or unreadable, will recompute. ({e})\")\n",
    "        if skip:\n",
    "            continue\n",
    "        print(f\"Estimating: {subject} ~ {model}\")\n",
    "        '''\n",
    "        \n",
    "        # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "        # Fit the mTRF\n",
    "        predictors_concatenated = subject_model_predictors[subject][model]\n",
    "        print('now boosting')\n",
    "        trf = eelbrain.boosting(eeg_padded, predictors_concatenated, -0.100, 1.000, \n",
    "                                error='l1', basis=0.050, partitions=5, test=1, selective_stopping=True)\n",
    "\n",
    "        # ————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "        # Save in directory\n",
    "        path = trf_paths[model]\n",
    "        eelbrain.save.pickle(trf, TRF_DIR / path)\n",
    "        print(f'TRF for {model} complete')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441dd0d4-f433-474e-9309-4e925c629880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32e2ea-ba38-47a3-8e9d-d07f6f0a2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Try padding EEG\n",
    "\n",
    "n_trials = 60\n",
    "sampling_rate = 64\n",
    "\n",
    "for subject in SUBJECTS:\n",
    "    # Extract the raw files\n",
    "    raw = mne.io.read_raw(EEG_DIR / f'{subject}' / f'{subject}-raw.fif', preload=True)\n",
    "    # Filter the raw data to the desired band\n",
    "    raw.filter(LOW_FREQUENCY, HIGH_FREQUENCY, n_jobs=1)\n",
    "    \n",
    "    eeg = eelbrain.load.mne.raw_ndvar(raw)\n",
    "    total_samples = eeg.shape[-1]\n",
    "    samples_per_trial = total_samples / n_trials\n",
    "    tstep = eeg.time.tstep\n",
    "    trial_duration = samples_per_trial * tstep\n",
    "\n",
    "    # Split by trial duration in seconds\n",
    "    trials = [eeg.sub(time=(i*trial_duration, (i+1)*trial_duration)) for i in range(n_trials)]\n",
    "    # Pad each trial relative to trial start\n",
    "    padded_trials = [eelbrain.pad(trial, tstart=-0.100, tstop=(trial.time.tmax - trial.time.tmin + 1.0)) for trial in trials]\n",
    "    # Reset time for each trial to start at 0\n",
    "    n_samples = padded_trials[0].shape[-1]\n",
    "    print(n_samples)\n",
    "    padded_trials = [eelbrain.set_time(trial, UTS(0, 1/sampling_rate, n_samples+1)) for trial in padded_trials]\n",
    "    # Concatenate\n",
    "    eeg_padded = eelbrain.concatenate(padded_trials)\n",
    "\n",
    "    print(f\"{subject}: padded EEG samples = {len(eeg_padded.time)}\") \n",
    "    print(f\"{subject}: padded EEG duration = {eeg_padded.time.tmax:.2f} s\") \n",
    "    print(trials[0], padded_trials[0])\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809970d-b10a-4653-892f-1e53ba8040a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eelbrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
